# simple-pretraining
심플 한국어 언어모델 사전학습

ref: [https://huggingface.co/transformers/examples.html](https://huggingface.co/transformers/examples.html)

## models
1. [BERT](https://github.com/deepvine/simple-pretraining/blob/main/simple-bert-training.py): simple BERT pre-training.
  - 한국어 Tokenizer: 형태소분석 + Wordpiece
3. BART: simple BART pre-training.
4. ALBERT: simple ALBERT pre-training
5. GPT-2: simple GPT-2 pre-training

## TO-DO list
